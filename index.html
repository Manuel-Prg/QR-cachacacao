<!DOCTYPE html>
<html>
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Visor de Modelos 3D</title>
    <!-- MindAR -->
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.1/dist/mindar-image.prod.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.1/dist/mindar-image-three.prod.js"></script>
    <!-- Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <!-- MediaPipe -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0"></script>
    <style>
        .container {
            position: relative;
            width: 100%;
            height: 100vh;
        }
        .ar-view {
            position: absolute;
            width: 100%;
            height: 100%;
        }
        .controls {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 1000;
            background: rgba(255,255,255,0.8);
            padding: 10px;
            border-radius: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="ar-view" id="ar-view"></div>
        <div class="controls">
            <button onclick="switchMode('image')">Modo Imagen</button>
            <button onclick="switchMode('hand')">Modo Mano</button>
            <button onclick="switchMode('face')">Modo Rostro</button>
        </div>
    </div>

    <script>
        let currentMode = null;
        let scene, camera, renderer;
        let model = null;

        // Inicializar Three.js
        function initThree() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.getElementById('ar-view').appendChild(renderer.domElement);
        }

        // Cargar modelo 3D (usando GLTFLoader)
        async function loadModel(url) {
            const loader = new THREE.GLTFLoader();
            return new Promise((resolve, reject) => {
                loader.load(url, (gltf) => {
                    model = gltf.scene;
                    resolve(model);
                }, undefined, reject);
            });
        }

        // Modo de detección de imagen con MindAR
        async function initImageMode() {
            const mindarThree = new window.MINDAR.IMAGE.MindARThree({
                container: document.querySelector("#ar-view"),
                imageTargetSrc: '/targets.mind',
            });

            const { renderer, scene, camera } = mindarThree;
            
            // Cargar y agregar tu modelo
            const modelUrl = '/tamborileros.glb';
            const model = await loadModel(modelUrl);
            scene.add(model);

            await mindarThree.start();
        }

        // Modo de detección de manos con MediaPipe
        async function initHandMode() {
            const vision = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
            );
            
            const handLandmarker = await HandLandmarker.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "path/to/hand_landmarker.task"
                },
                numHands: 2
            });

            // Configurar la cámara web y el procesamiento
            const video = document.createElement('video');
            // ... configuración de la cámara web ...
        }

        // Modo de detección facial con MediaPipe
        async function initFaceMode() {
            const vision = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
            );
            
            const faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "path/to/face_landmarker.task"
                },
                numFaces: 1
            });

            // Configurar la cámara web y el procesamiento
            const video = document.createElement('video');
            // ... configuración de la cámara web ...
        }

        // Cambiar entre modos
        async function switchMode(mode) {
            if (currentMode === mode) return;
            
            // Limpiar modo actual
            if (currentMode) {
                // Limpiar recursos del modo actual
            }

            currentMode = mode;
            
            switch(mode) {
                case 'image':
                    await initImageMode();
                    break;
                case 'hand':
                    await initHandMode();
                    break;
                case 'face':
                    await initFaceMode();
                    break;
            }
        }

        // Inicializar la aplicación
        initThree();
        switchMode('image'); // Comenzar en modo imagen por defecto
    </script>
</body>
</html>